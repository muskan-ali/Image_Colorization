{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#Normalize images (divide by 255)\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#Resizing images\n",
    "train = train_datagen.flow_from_directory('images/train_images/', \n",
    "                                          target_size=(256, 256),\n",
    "                                          class_mode=None)\n",
    "\n",
    "#Convert from RGB to Lab\n",
    "\"\"\"\n",
    "by iterating on each image, we convert the RGB to Lab. \n",
    "Think of LAB image as a grey image in L channel and all color info stored in A and B channels. \n",
    "The input to the network will be the L channel, so we assign L channel to X vector. \n",
    "And assign A and B to Y.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X =[]\n",
    "Y =[]\n",
    "for img in train[0]:\n",
    "  try:\n",
    "      lab = rgb2lab(img)\n",
    "      X.append(lab[:,:,0]) \n",
    "      Y.append(lab[:,:,1:] / 128) #A and B values range from -127 to 128, \n",
    "      #so we divide the values by 128 to restrict values to between -1 and 1.\n",
    "  except:\n",
    "     print('error')\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "\n",
    "#Encoder\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "\n",
    "#Decoder\n",
    "#For the last layer we use tanh instead of Relu. \n",
    "#This is because we are colorizing the image in this layer using 2 filters, A and B.\n",
    "#A and B values range between -1 and 1 so tanh (or hyperbolic tangent) is used\n",
    "#as it also has the range between -1 and 1. \n",
    "#Other functions go from 0 to 1.\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X,Y,validation_split=0.1, epochs=300, batch_size=16)\n",
    "\n",
    "model.save('colorize_autoencoder_VGG16_300.model')\n",
    "\n",
    "\n",
    "###########################################################\n",
    "#Load saved model and test on images.\n",
    "#colorize_autoencoder300.model is trained on 300 epochs\n",
    "#\n",
    "\n",
    "tf.keras.models.load_model(\n",
    "    'colorize_autoencoder_VGG16_300.model',\n",
    "    custom_objects=None,\n",
    "    compile=True)\n",
    "\n",
    "\n",
    "img1_color=[]\n",
    "img1=img_to_array(load_img('images/test_images/sunset.png'))\n",
    "\n",
    "img1 = resize(img1 ,(256,256))\n",
    "img1_color.append(img1)\n",
    "img1_color = np.array(img1_color, dtype=float)\n",
    "img1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
    "img1_color = img1_color.reshape(img1_color.shape+(1,))\n",
    "\n",
    "output1 = model.predict(img1_color)\n",
    "output1 = output1*128\n",
    "result = np.zeros((256, 256, 3))\n",
    "result[:,:,0] = img1_color[0][:,:,0]\n",
    "result[:,:,1:] = output1[0]\n",
    "imsave(\"result_images/result.png\", lab2rgb(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
